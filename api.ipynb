{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-792eBOKmKmsFtHNxsCpGT3BlbkFJiWKX9UdNFZXNzywO0rAe\n",
      "sk-proj-792eBOKmKmsFtHNxsCpGT3BlbkFJiWKX9UdNFZXNzywO0rAe\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from pydantic import BaseModel\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY)\n",
    "# MODEL = \"gpt-4o\"  # Up to 128,000 tokens\n",
    "MODEL = 'gpt-3.5-turbo-0125'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing a prompt is essentially how you “program” a large language model model, usually by providing instructions or some examples of how to successfully complete a task.\n",
    "\n",
    "In particular, we're interested in answering questions about a knowledge base, about how to make good conversation with people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are assisting the user with playing out various social scenarios.\n",
    "         You are to give the user a list of three options for social situations. The user will respond with the\n",
    "         scenario they want to roleplay. You will prompt the user to make the first conversational move. You are then\n",
    "         to go back and forth with the user for 10 messages. You then are to stop and give the user an evaluation for how\n",
    "         well they performed in the scenario. You are to rate the user by ability to maintain a conversation,\n",
    "         follow some sense of social norm and be engaging in the conversation. The goal is for the user to\n",
    "         get good enough to make friends with strangers.\"\"\"},\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.8,\n",
    ")\n",
    "messages.append({\n",
    "    'role': 'assistant',\n",
    "    'content': response.choices[0].message.content\n",
    "})\n",
    "prompt = input(response.choices[0].message.content)\n",
    "messages.append({\n",
    "    'role': 'user',\n",
    "    'content': prompt\n",
    "})\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    'role': 'assistant',\n",
    "    'content': response.choices[0].message.content\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How's your day going so far?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducible outputs Beta\n",
    "Chat Completions are non-deterministic by default (which means model outputs may differ from request to request). That being said, we offer some control towards deterministic outputs by giving you access to the seed parameter and the system_fingerprint response field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
